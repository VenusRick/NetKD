
======================================================================
NetKD训练 - 使用真实数据集
======================================================================
数据集: ISCXVPN2016
数据路径: /walnut_data/yqm/Dataset
训练模式: full_pipeline
设备: cuda
======================================================================

正在加载数据集...
Loading dataset from: /walnut_data/yqm/Dataset/ISCXVPN2016
Found 7 classes: ['browsing', 'chat', 'email', 'ftp', 'p2p', 'streaming', 'voip']
  Class 'browsing': 1697 images
  Class 'chat': 4000 images
  Class 'email': 598 images
  Class 'ftp': 1949 images
  Class 'p2p': 922 images
  Class 'streaming': 666 images
  Class 'voip': 4000 images

Total images loaded: 13832
Number of classes: 7

Dataset split:
  Train: 9682 images (70.0%)
  Val:   2075 images (15.0%)
  Test:  2075 images (15.0%)

Image dimensions: 1 x 40 x 40

数据集加载完成！
  类别数: 7
  训练集: 9682 样本
  验证集: 2075 样本
  测试集: 2075 样本
  图像尺寸: 1x40x40
  类别名称: ['browsing', 'chat', 'email', 'ftp', 'p2p', 'streaming', 'voip']


======================================================================
阶段 I: 训练教师模型
======================================================================

[Monitor] >>> Stage 'teacher_resnet50' started (20 epochs)
[Teacher resnet50] epoch=1 train_loss=1.6095 val_loss=1.8842 val_acc=0.2916
[Monitor][teacher_resnet50] epoch 1/20 | train_loss=1.6095 | val_loss=1.8842 | val_acc=0.2916
[Teacher resnet50] epoch=2 train_loss=0.5725 val_loss=2.9759 val_acc=0.0786
[Monitor][teacher_resnet50] epoch 2/20 | train_loss=0.5725 | val_loss=2.9759 | val_acc=0.0786 | Δacc=-0.2130
[Teacher resnet50] epoch=3 train_loss=0.3392 val_loss=4.9820 val_acc=0.0660
[Monitor][teacher_resnet50] epoch 3/20 | train_loss=0.3392 | val_loss=4.9820 | val_acc=0.0660 | Δacc=-0.0125
[Teacher resnet50] epoch=4 train_loss=0.2410 val_loss=3.1912 val_acc=0.3017
[Monitor][teacher_resnet50] epoch 4/20 | train_loss=0.2410 | val_loss=3.1912 | val_acc=0.3017 | Δacc=+0.2357
[Teacher resnet50] epoch=5 train_loss=0.2161 val_loss=0.4630 val_acc=0.8689
[Monitor][teacher_resnet50] epoch 5/20 | train_loss=0.2161 | val_loss=0.4630 | val_acc=0.8689 | Δacc=+0.5672
[Teacher resnet50] epoch=6 train_loss=0.1939 val_loss=0.3253 val_acc=0.8896
[Monitor][teacher_resnet50] epoch 6/20 | train_loss=0.1939 | val_loss=0.3253 | val_acc=0.8896 | Δacc=+0.0207
[Teacher resnet50] epoch=7 train_loss=0.1778 val_loss=0.6461 val_acc=0.8978
[Monitor][teacher_resnet50] epoch 7/20 | train_loss=0.1778 | val_loss=0.6461 | val_acc=0.8978 | Δacc=+0.0082
[Teacher resnet50] epoch=8 train_loss=0.1422 val_loss=0.3123 val_acc=0.9027
[Monitor][teacher_resnet50] epoch 8/20 | train_loss=0.1422 | val_loss=0.3123 | val_acc=0.9027 | Δacc=+0.0048
[Teacher resnet50] epoch=9 train_loss=0.1262 val_loss=0.6743 val_acc=0.8983
[Monitor][teacher_resnet50] epoch 9/20 | train_loss=0.1262 | val_loss=0.6743 | val_acc=0.8983 | Δacc=-0.0043
[Teacher resnet50] epoch=10 train_loss=0.1382 val_loss=0.3354 val_acc=0.8814
[Monitor][teacher_resnet50] epoch 10/20 | train_loss=0.1382 | val_loss=0.3354 | val_acc=0.8814 | Δacc=-0.0169
[Teacher resnet50] epoch=11 train_loss=0.1744 val_loss=0.2519 val_acc=0.9089
[Monitor][teacher_resnet50] epoch 11/20 | train_loss=0.1744 | val_loss=0.2519 | val_acc=0.9089 | Δacc=+0.0275
[Teacher resnet50] epoch=12 train_loss=0.1119 val_loss=0.2463 val_acc=0.9200
[Monitor][teacher_resnet50] epoch 12/20 | train_loss=0.1119 | val_loss=0.2463 | val_acc=0.9200 | Δacc=+0.0111
[Teacher resnet50] epoch=13 train_loss=0.0705 val_loss=0.2183 val_acc=0.9345
[Monitor][teacher_resnet50] epoch 13/20 | train_loss=0.0705 | val_loss=0.2183 | val_acc=0.9345 | Δacc=+0.0145
[Teacher resnet50] epoch=14 train_loss=0.0511 val_loss=0.2495 val_acc=0.9311
[Monitor][teacher_resnet50] epoch 14/20 | train_loss=0.0511 | val_loss=0.2495 | val_acc=0.9311 | Δacc=-0.0034
[Teacher resnet50] epoch=15 train_loss=0.0509 val_loss=0.2530 val_acc=0.9316
[Monitor][teacher_resnet50] epoch 15/20 | train_loss=0.0509 | val_loss=0.2530 | val_acc=0.9316 | Δacc=+0.0005
[Teacher resnet50] epoch=16 train_loss=0.0450 val_loss=0.2763 val_acc=0.9373
[Monitor][teacher_resnet50] epoch 16/20 | train_loss=0.0450 | val_loss=0.2763 | val_acc=0.9373 | Δacc=+0.0058
[Teacher resnet50] epoch=17 train_loss=0.0367 val_loss=0.2290 val_acc=0.9277
[Monitor][teacher_resnet50] epoch 17/20 | train_loss=0.0367 | val_loss=0.2290 | val_acc=0.9277 | Δacc=-0.0096
[Teacher resnet50] epoch=18 train_loss=0.0299 val_loss=0.2247 val_acc=0.9349
[Monitor][teacher_resnet50] epoch 18/20 | train_loss=0.0299 | val_loss=0.2247 | val_acc=0.9349 | Δacc=+0.0072
[Teacher resnet50] epoch=19 train_loss=0.0305 val_loss=0.2263 val_acc=0.9316
[Monitor][teacher_resnet50] epoch 19/20 | train_loss=0.0305 | val_loss=0.2263 | val_acc=0.9316 | Δacc=-0.0034
[Teacher resnet50] epoch=20 train_loss=0.0352 val_loss=0.2510 val_acc=0.9282
[Monitor][teacher_resnet50] epoch 20/20 | train_loss=0.0352 | val_loss=0.2510 | val_acc=0.9282 | Δacc=-0.0034
[Monitor] <<< Stage 'teacher_resnet50' finished after 20 epochs | final acc=0.9282
[Monitor] >>> Stage 'teacher_mbv3' started (20 epochs)
[Teacher mbv3] epoch=1 train_loss=1.2842 val_loss=1.8805 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 1/20 | train_loss=1.2842 | val_loss=1.8805 | val_acc=0.2892
[Teacher mbv3] epoch=2 train_loss=0.5613 val_loss=1.8784 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 2/20 | train_loss=0.5613 | val_loss=1.8784 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=3 train_loss=0.3060 val_loss=1.8628 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 3/20 | train_loss=0.3060 | val_loss=1.8628 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=4 train_loss=0.1896 val_loss=1.8440 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 4/20 | train_loss=0.1896 | val_loss=1.8440 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=5 train_loss=0.1570 val_loss=1.8280 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 5/20 | train_loss=0.1570 | val_loss=1.8280 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=6 train_loss=0.1558 val_loss=1.8121 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 6/20 | train_loss=0.1558 | val_loss=1.8121 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=7 train_loss=0.1364 val_loss=1.8020 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 7/20 | train_loss=0.1364 | val_loss=1.8020 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=8 train_loss=0.0839 val_loss=1.8014 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 8/20 | train_loss=0.0839 | val_loss=1.8014 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=9 train_loss=0.0635 val_loss=1.8058 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 9/20 | train_loss=0.0635 | val_loss=1.8058 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=10 train_loss=0.0676 val_loss=1.8013 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 10/20 | train_loss=0.0676 | val_loss=1.8013 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=11 train_loss=0.0711 val_loss=1.8076 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 11/20 | train_loss=0.0711 | val_loss=1.8076 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=12 train_loss=0.0620 val_loss=1.8177 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 12/20 | train_loss=0.0620 | val_loss=1.8177 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=13 train_loss=0.0456 val_loss=1.8356 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 13/20 | train_loss=0.0456 | val_loss=1.8356 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=14 train_loss=0.0412 val_loss=1.8225 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 14/20 | train_loss=0.0412 | val_loss=1.8225 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=15 train_loss=0.0356 val_loss=1.8109 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 15/20 | train_loss=0.0356 | val_loss=1.8109 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=16 train_loss=0.0354 val_loss=1.8319 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 16/20 | train_loss=0.0354 | val_loss=1.8319 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=17 train_loss=0.0324 val_loss=1.8316 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 17/20 | train_loss=0.0324 | val_loss=1.8316 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=18 train_loss=0.0424 val_loss=1.8263 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 18/20 | train_loss=0.0424 | val_loss=1.8263 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=19 train_loss=0.0449 val_loss=1.8544 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 19/20 | train_loss=0.0449 | val_loss=1.8544 | val_acc=0.2892 | Δacc=+0.0000
[Teacher mbv3] epoch=20 train_loss=0.0510 val_loss=1.8043 val_acc=0.2892
[Monitor][teacher_mbv3] epoch 20/20 | train_loss=0.0510 | val_loss=1.8043 | val_acc=0.2892 | Δacc=+0.0000
[Monitor] <<< Stage 'teacher_mbv3' finished after 20 epochs | final acc=0.2892
[Monitor] >>> Stage 'teacher_densenet121' started (20 epochs)
[Teacher densenet121] epoch=1 train_loss=0.7849 val_loss=2.1130 val_acc=0.1407
[Monitor][teacher_densenet121] epoch 1/20 | train_loss=0.7849 | val_loss=2.1130 | val_acc=0.1407
[Teacher densenet121] epoch=2 train_loss=0.3178 val_loss=3.2021 val_acc=0.1576
[Monitor][teacher_densenet121] epoch 2/20 | train_loss=0.3178 | val_loss=3.2021 | val_acc=0.1576 | Δacc=+0.0169
[Teacher densenet121] epoch=3 train_loss=0.2062 val_loss=2.6354 val_acc=0.4689
[Monitor][teacher_densenet121] epoch 3/20 | train_loss=0.2062 | val_loss=2.6354 | val_acc=0.4689 | Δacc=+0.3113
[Teacher densenet121] epoch=4 train_loss=0.1852 val_loss=0.4236 val_acc=0.8627
[Monitor][teacher_densenet121] epoch 4/20 | train_loss=0.1852 | val_loss=0.4236 | val_acc=0.8627 | Δacc=+0.3937
[Teacher densenet121] epoch=5 train_loss=0.1490 val_loss=0.3238 val_acc=0.8949
[Monitor][teacher_densenet121] epoch 5/20 | train_loss=0.1490 | val_loss=0.3238 | val_acc=0.8949 | Δacc=+0.0323
[Teacher densenet121] epoch=6 train_loss=0.1151 val_loss=0.2418 val_acc=0.9161
[Monitor][teacher_densenet121] epoch 6/20 | train_loss=0.1151 | val_loss=0.2418 | val_acc=0.9161 | Δacc=+0.0212
[Teacher densenet121] epoch=7 train_loss=0.1011 val_loss=0.3990 val_acc=0.8771
[Monitor][teacher_densenet121] epoch 7/20 | train_loss=0.1011 | val_loss=0.3990 | val_acc=0.8771 | Δacc=-0.0390
[Teacher densenet121] epoch=8 train_loss=0.0787 val_loss=0.2324 val_acc=0.9161
[Monitor][teacher_densenet121] epoch 8/20 | train_loss=0.0787 | val_loss=0.2324 | val_acc=0.9161 | Δacc=+0.0390
[Teacher densenet121] epoch=9 train_loss=0.0739 val_loss=0.3366 val_acc=0.8757
[Monitor][teacher_densenet121] epoch 9/20 | train_loss=0.0739 | val_loss=0.3366 | val_acc=0.8757 | Δacc=-0.0405
[Teacher densenet121] epoch=10 train_loss=0.0602 val_loss=0.6043 val_acc=0.8805
[Monitor][teacher_densenet121] epoch 10/20 | train_loss=0.0602 | val_loss=0.6043 | val_acc=0.8805 | Δacc=+0.0048
[Teacher densenet121] epoch=11 train_loss=0.0570 val_loss=0.3110 val_acc=0.9118
[Monitor][teacher_densenet121] epoch 11/20 | train_loss=0.0570 | val_loss=0.3110 | val_acc=0.9118 | Δacc=+0.0313
[Teacher densenet121] epoch=12 train_loss=0.0658 val_loss=0.2696 val_acc=0.9084
[Monitor][teacher_densenet121] epoch 12/20 | train_loss=0.0658 | val_loss=0.2696 | val_acc=0.9084 | Δacc=-0.0034
[Teacher densenet121] epoch=13 train_loss=0.0500 val_loss=0.2584 val_acc=0.9214
[Monitor][teacher_densenet121] epoch 13/20 | train_loss=0.0500 | val_loss=0.2584 | val_acc=0.9214 | Δacc=+0.0130
[Teacher densenet121] epoch=14 train_loss=0.0311 val_loss=0.1856 val_acc=0.9359
[Monitor][teacher_densenet121] epoch 14/20 | train_loss=0.0311 | val_loss=0.1856 | val_acc=0.9359 | Δacc=+0.0145
[Teacher densenet121] epoch=15 train_loss=0.0435 val_loss=0.2602 val_acc=0.9142
[Monitor][teacher_densenet121] epoch 15/20 | train_loss=0.0435 | val_loss=0.2602 | val_acc=0.9142 | Δacc=-0.0217
[Teacher densenet121] epoch=16 train_loss=0.0347 val_loss=0.4422 val_acc=0.9070
[Monitor][teacher_densenet121] epoch 16/20 | train_loss=0.0347 | val_loss=0.4422 | val_acc=0.9070 | Δacc=-0.0072
[Teacher densenet121] epoch=17 train_loss=0.0329 val_loss=0.2862 val_acc=0.9195
[Monitor][teacher_densenet121] epoch 17/20 | train_loss=0.0329 | val_loss=0.2862 | val_acc=0.9195 | Δacc=+0.0125
[Teacher densenet121] epoch=18 train_loss=0.0246 val_loss=0.2802 val_acc=0.9210
[Monitor][teacher_densenet121] epoch 18/20 | train_loss=0.0246 | val_loss=0.2802 | val_acc=0.9210 | Δacc=+0.0014
[Teacher densenet121] epoch=19 train_loss=0.0249 val_loss=0.2588 val_acc=0.9205
[Monitor][teacher_densenet121] epoch 19/20 | train_loss=0.0249 | val_loss=0.2588 | val_acc=0.9205 | Δacc=-0.0005
[Teacher densenet121] epoch=20 train_loss=0.0216 val_loss=0.1968 val_acc=0.9402
[Monitor][teacher_densenet121] epoch 20/20 | train_loss=0.0216 | val_loss=0.1968 | val_acc=0.9402 | Δacc=+0.0198
[Monitor] <<< Stage 'teacher_densenet121' finished after 20 epochs | final acc=0.9402

✅ 教师模型训练完成！检查点已保存到: runs/ISCXVPN2016_high

======================================================================
阶段 II: 训练Stacking集成模型
======================================================================

[Monitor] >>> Stage 'stacking' started (15 epochs)
[Stacking] epoch=1 train_loss=0.4007 val_loss=0.1307 val_acc=0.9489
[Monitor][stacking] epoch 1/15 | train_loss=0.4007 | val_loss=0.1307 | val_acc=0.9489
[Stacking] epoch=2 train_loss=0.0172 val_loss=0.1289 val_acc=0.9504
[Monitor][stacking] epoch 2/15 | train_loss=0.0172 | val_loss=0.1289 | val_acc=0.9504 | Δacc=+0.0014
[Stacking] epoch=3 train_loss=0.0104 val_loss=0.1347 val_acc=0.9537
[Monitor][stacking] epoch 3/15 | train_loss=0.0104 | val_loss=0.1347 | val_acc=0.9537 | Δacc=+0.0034
[Stacking] epoch=4 train_loss=0.0087 val_loss=0.1377 val_acc=0.9552
[Monitor][stacking] epoch 4/15 | train_loss=0.0087 | val_loss=0.1377 | val_acc=0.9552 | Δacc=+0.0014
[Stacking] epoch=5 train_loss=0.0078 val_loss=0.1404 val_acc=0.9552
[Monitor][stacking] epoch 5/15 | train_loss=0.0078 | val_loss=0.1404 | val_acc=0.9552 | Δacc=+0.0000
[Stacking] epoch=6 train_loss=0.0072 val_loss=0.1423 val_acc=0.9542
[Monitor][stacking] epoch 6/15 | train_loss=0.0072 | val_loss=0.1423 | val_acc=0.9542 | Δacc=-0.0010
[Stacking] epoch=7 train_loss=0.0067 val_loss=0.1453 val_acc=0.9533
[Monitor][stacking] epoch 7/15 | train_loss=0.0067 | val_loss=0.1453 | val_acc=0.9533 | Δacc=-0.0010
[Stacking] epoch=8 train_loss=0.0062 val_loss=0.1475 val_acc=0.9533
[Monitor][stacking] epoch 8/15 | train_loss=0.0062 | val_loss=0.1475 | val_acc=0.9533 | Δacc=+0.0000
[Stacking] epoch=9 train_loss=0.0058 val_loss=0.1505 val_acc=0.9528
[Monitor][stacking] epoch 9/15 | train_loss=0.0058 | val_loss=0.1505 | val_acc=0.9528 | Δacc=-0.0005
[Stacking] epoch=10 train_loss=0.0056 val_loss=0.1531 val_acc=0.9528
[Monitor][stacking] epoch 10/15 | train_loss=0.0056 | val_loss=0.1531 | val_acc=0.9528 | Δacc=+0.0000
[Stacking] epoch=11 train_loss=0.0053 val_loss=0.1552 val_acc=0.9523
[Monitor][stacking] epoch 11/15 | train_loss=0.0053 | val_loss=0.1552 | val_acc=0.9523 | Δacc=-0.0005
[Stacking] epoch=12 train_loss=0.0051 val_loss=0.1585 val_acc=0.9528
[Monitor][stacking] epoch 12/15 | train_loss=0.0051 | val_loss=0.1585 | val_acc=0.9528 | Δacc=+0.0005
[Stacking] epoch=13 train_loss=0.0048 val_loss=0.1609 val_acc=0.9513
[Monitor][stacking] epoch 13/15 | train_loss=0.0048 | val_loss=0.1609 | val_acc=0.9513 | Δacc=-0.0014
[Stacking] epoch=14 train_loss=0.0047 val_loss=0.1636 val_acc=0.9513
[Monitor][stacking] epoch 14/15 | train_loss=0.0047 | val_loss=0.1636 | val_acc=0.9513 | Δacc=+0.0000
[Stacking] epoch=15 train_loss=0.0045 val_loss=0.1651 val_acc=0.9513
[Monitor][stacking] epoch 15/15 | train_loss=0.0045 | val_loss=0.1651 | val_acc=0.9513 | Δacc=+0.0000
[Monitor] <<< Stage 'stacking' finished after 15 epochs | final acc=0.9513

✅ Stacking模型训练完成！检查点: runs/ISCXVPN2016_high/stacking_model.pth

======================================================================
阶段 III: 训练学生模型（知识蒸馏）
======================================================================

蒸馏损失配置:
  CE权重: 1.5
  FKL权重: 0.5
  RKL权重: 0.5
  Sinkhorn权重: 0.05
  温度: 3.0

[Monitor] >>> Stage 'student' started (40 epochs)
[Student] epoch=1 train_loss=3.1640 val_loss=4.0852 val_acc=0.2892
[Monitor][student] epoch 1/40 | train_loss=3.1640 | val_loss=4.0852 | val_acc=0.2892
[Student] epoch=2 train_loss=1.9054 val_loss=2.5811 val_acc=0.1778
[Monitor][student] epoch 2/40 | train_loss=1.9054 | val_loss=2.5811 | val_acc=0.1778 | Δacc=-0.1113
[Student] epoch=3 train_loss=1.4105 val_loss=2.1206 val_acc=0.3258
[Monitor][student] epoch 3/40 | train_loss=1.4105 | val_loss=2.1206 | val_acc=0.3258 | Δacc=+0.1480
[Student] epoch=4 train_loss=1.1347 val_loss=0.7687 val_acc=0.7639
[Monitor][student] epoch 4/40 | train_loss=1.1347 | val_loss=0.7687 | val_acc=0.7639 | Δacc=+0.4381
[Student] epoch=5 train_loss=0.9398 val_loss=0.6673 val_acc=0.8087
[Monitor][student] epoch 5/40 | train_loss=0.9398 | val_loss=0.6673 | val_acc=0.8087 | Δacc=+0.0448
[Student] epoch=6 train_loss=0.7924 val_loss=0.6293 val_acc=0.8255
[Monitor][student] epoch 6/40 | train_loss=0.7924 | val_loss=0.6293 | val_acc=0.8255 | Δacc=+0.0169
[Student] epoch=7 train_loss=0.7328 val_loss=0.6341 val_acc=0.8308
[Monitor][student] epoch 7/40 | train_loss=0.7328 | val_loss=0.6341 | val_acc=0.8308 | Δacc=+0.0053
[Student] epoch=8 train_loss=0.6863 val_loss=0.6832 val_acc=0.8265
[Monitor][student] epoch 8/40 | train_loss=0.6863 | val_loss=0.6832 | val_acc=0.8265 | Δacc=-0.0043
[Student] epoch=9 train_loss=0.6114 val_loss=0.5866 val_acc=0.8386
[Monitor][student] epoch 9/40 | train_loss=0.6114 | val_loss=0.5866 | val_acc=0.8386 | Δacc=+0.0120
[Student] epoch=10 train_loss=0.5408 val_loss=0.7110 val_acc=0.8376
[Monitor][student] epoch 10/40 | train_loss=0.5408 | val_loss=0.7110 | val_acc=0.8376 | Δacc=-0.0010
[Student] epoch=11 train_loss=0.6384 val_loss=0.7176 val_acc=0.8410
[Monitor][student] epoch 11/40 | train_loss=0.6384 | val_loss=0.7176 | val_acc=0.8410 | Δacc=+0.0034
[Student] epoch=12 train_loss=0.6925 val_loss=0.6389 val_acc=0.8371
[Monitor][student] epoch 12/40 | train_loss=0.6925 | val_loss=0.6389 | val_acc=0.8371 | Δacc=-0.0039
[Student] epoch=13 train_loss=0.6765 val_loss=0.6013 val_acc=0.8525
[Monitor][student] epoch 13/40 | train_loss=0.6765 | val_loss=0.6013 | val_acc=0.8525 | Δacc=+0.0154
[Student] epoch=14 train_loss=0.6182 val_loss=0.6003 val_acc=0.8424
[Monitor][student] epoch 14/40 | train_loss=0.6182 | val_loss=0.6003 | val_acc=0.8424 | Δacc=-0.0101
[Student] epoch=15 train_loss=0.6439 val_loss=0.5680 val_acc=0.8593
[Monitor][student] epoch 15/40 | train_loss=0.6439 | val_loss=0.5680 | val_acc=0.8593 | Δacc=+0.0169
[Student] epoch=16 train_loss=0.5349 val_loss=0.6630 val_acc=0.8549
[Monitor][student] epoch 16/40 | train_loss=0.5349 | val_loss=0.6630 | val_acc=0.8549 | Δacc=-0.0043
[Student] epoch=17 train_loss=0.5784 val_loss=0.6531 val_acc=0.8443
[Monitor][student] epoch 17/40 | train_loss=0.5784 | val_loss=0.6531 | val_acc=0.8443 | Δacc=-0.0106
[Student] epoch=18 train_loss=0.5326 val_loss=0.7082 val_acc=0.8419
[Monitor][student] epoch 18/40 | train_loss=0.5326 | val_loss=0.7082 | val_acc=0.8419 | Δacc=-0.0024
[Student] epoch=19 train_loss=0.7276 val_loss=0.5845 val_acc=0.8424
[Monitor][student] epoch 19/40 | train_loss=0.7276 | val_loss=0.5845 | val_acc=0.8424 | Δacc=+0.0005
[Student] epoch=20 train_loss=0.8244 val_loss=0.7300 val_acc=0.8202
[Monitor][student] epoch 20/40 | train_loss=0.8244 | val_loss=0.7300 | val_acc=0.8202 | Δacc=-0.0222
[Student] epoch=21 train_loss=1.0702 val_loss=0.8827 val_acc=0.7672
[Monitor][student] epoch 21/40 | train_loss=1.0702 | val_loss=0.8827 | val_acc=0.7672 | Δacc=-0.0530
[Student] epoch=22 train_loss=1.1909 val_loss=0.7677 val_acc=0.7884
[Monitor][student] epoch 22/40 | train_loss=1.1909 | val_loss=0.7677 | val_acc=0.7884 | Δacc=+0.0212
[Student] epoch=23 train_loss=1.6235 val_loss=1.2223 val_acc=0.6940
[Monitor][student] epoch 23/40 | train_loss=1.6235 | val_loss=1.2223 | val_acc=0.6940 | Δacc=-0.0945
[Student] epoch=24 train_loss=21.4151 val_loss=59.1159 val_acc=0.3311
[Monitor][student] epoch 24/40 | train_loss=21.4151 | val_loss=59.1159 | val_acc=0.3311 | Δacc=-0.3629
[Student] epoch=25 train_loss=63.0549 val_loss=25.2785 val_acc=0.3504
[Monitor][student] epoch 25/40 | train_loss=63.0549 | val_loss=25.2785 | val_acc=0.3504 | Δacc=+0.0193
[Student] epoch=26 train_loss=47.9244 val_loss=23.2894 val_acc=0.3017
[Monitor][student] epoch 26/40 | train_loss=47.9244 | val_loss=23.2894 | val_acc=0.3017 | Δacc=-0.0487
[Student] epoch=27 train_loss=66.3886 val_loss=62.4101 val_acc=0.2096
[Monitor][student] epoch 27/40 | train_loss=66.3886 | val_loss=62.4101 | val_acc=0.2096 | Δacc=-0.0920
[Student] epoch=28 train_loss=93.4120 val_loss=22.7502 val_acc=0.2169
[Monitor][student] epoch 28/40 | train_loss=93.4120 | val_loss=22.7502 | val_acc=0.2169 | Δacc=+0.0072
[Student] epoch=29 train_loss=39.7411 val_loss=13.3223 val_acc=0.2733
[Monitor][student] epoch 29/40 | train_loss=39.7411 | val_loss=13.3223 | val_acc=0.2733 | Δacc=+0.0564
[Student] epoch=30 train_loss=10.3836 val_loss=2.4387 val_acc=0.3205
[Monitor][student] epoch 30/40 | train_loss=10.3836 | val_loss=2.4387 | val_acc=0.3205 | Δacc=+0.0472
[Student] epoch=31 train_loss=4.0562 val_loss=1.6313 val_acc=0.3682
[Monitor][student] epoch 31/40 | train_loss=4.0562 | val_loss=1.6313 | val_acc=0.3682 | Δacc=+0.0477
[Student] epoch=32 train_loss=3.5444 val_loss=1.5661 val_acc=0.4173
[Monitor][student] epoch 32/40 | train_loss=3.5444 | val_loss=1.5661 | val_acc=0.4173 | Δacc=+0.0492
[Student] epoch=33 train_loss=3.3992 val_loss=1.4854 val_acc=0.4593
[Monitor][student] epoch 33/40 | train_loss=3.3992 | val_loss=1.4854 | val_acc=0.4593 | Δacc=+0.0419
[Student] epoch=34 train_loss=3.3142 val_loss=1.4964 val_acc=0.4395
[Monitor][student] epoch 34/40 | train_loss=3.3142 | val_loss=1.4964 | val_acc=0.4395 | Δacc=-0.0198
[Student] epoch=35 train_loss=3.2630 val_loss=1.4687 val_acc=0.4684
[Monitor][student] epoch 35/40 | train_loss=3.2630 | val_loss=1.4687 | val_acc=0.4684 | Δacc=+0.0289
[Student] epoch=36 train_loss=3.2201 val_loss=1.4486 val_acc=0.4737
[Monitor][student] epoch 36/40 | train_loss=3.2201 | val_loss=1.4486 | val_acc=0.4737 | Δacc=+0.0053
[Student] epoch=37 train_loss=3.1761 val_loss=1.4133 val_acc=0.4665
[Monitor][student] epoch 37/40 | train_loss=3.1761 | val_loss=1.4133 | val_acc=0.4665 | Δacc=-0.0072
[Student] epoch=38 train_loss=3.1584 val_loss=1.3912 val_acc=0.4665
[Monitor][student] epoch 38/40 | train_loss=3.1584 | val_loss=1.3912 | val_acc=0.4665 | Δacc=+0.0000
[Student] epoch=39 train_loss=3.1694 val_loss=1.4176 val_acc=0.4598
[Monitor][student] epoch 39/40 | train_loss=3.1694 | val_loss=1.4176 | val_acc=0.4598 | Δacc=-0.0067
[Student] epoch=40 train_loss=3.1184 val_loss=1.3770 val_acc=0.4863
[Monitor][student] epoch 40/40 | train_loss=3.1184 | val_loss=1.3770 | val_acc=0.4863 | Δacc=+0.0265
[Monitor] <<< Stage 'student' finished after 40 epochs | final acc=0.4863

✅ 学生模型训练完成！检查点: runs/ISCXVPN2016_high/student_sd_mkd.pth

======================================================================
评估学生模型
======================================================================


测试集结果:
  准确率: 0.5012
  F1分数: 0.4928

混淆矩阵:
tensor([[128,  11,   5,  38,  16,   4,  53],
        [  6, 322,   4,  23,   6,   3, 236],
        [  0,  21,  10,  19,   4,   7,  29],
        [ 10,  24,  12, 166,  46,   7,  27],
        [  6,  22,   1,  39,  35,   6,  29],
        [ 10,   6,   7,  39,  12,  13,  13],
        [ 12, 178,   3,  27,  12,   2, 366]])

结果已保存到: runs/ISCXVPN2016_high/results_ISCXVPN2016.json

======================================================================
训练完成！
======================================================================

