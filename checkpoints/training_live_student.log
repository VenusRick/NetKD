
======================================================================
NetKD训练 - 使用真实数据集
======================================================================
数据集: ISCXVPN2016
数据路径: /walnut_data/yqm/Dataset
训练模式: train_student
设备: cuda
======================================================================

正在加载数据集...
Loading dataset from: /walnut_data/yqm/Dataset/ISCXVPN2016
Found 7 classes: ['browsing', 'chat', 'email', 'ftp', 'p2p', 'streaming', 'voip']
  Class 'browsing': 1697 images
  Class 'chat': 4000 images
  Class 'email': 598 images
  Class 'ftp': 1949 images
  Class 'p2p': 922 images
  Class 'streaming': 666 images
  Class 'voip': 4000 images

Total images loaded: 13832
Number of classes: 7

Dataset split:
  Train: 11064 images (80.0%)
  Val:   1384 images (10.0%)
  Test:  1384 images (10.0%)

Image dimensions: 1 x 40 x 40

数据集加载完成！
  类别数: 7
  训练集: 11064 样本
  验证集: 1384 样本
  测试集: 1384 样本
  图像尺寸: 1x40x40
  类别名称: ['browsing', 'chat', 'email', 'ftp', 'p2p', 'streaming', 'voip']


======================================================================
阶段 III: 训练学生模型（知识蒸馏）
======================================================================

蒸馏损失配置:
  CE权重: 1.2
  FKL权重: 0.8
  RKL权重: 0.2
  Sinkhorn权重: 0.02
  温度: 4.0

[Monitor] >>> Stage 'student' started (60 epochs)
[Student] epoch=1 train_loss=2.6911 val_loss=1.9965 val_acc=0.3591
[Monitor][student] epoch 1/60 | train_loss=2.6911 | val_loss=1.9965 | val_acc=0.3591
[Student] epoch=2 train_loss=1.8619 val_loss=0.9756 val_acc=0.7095
[Monitor][student] epoch 2/60 | train_loss=1.8619 | val_loss=0.9756 | val_acc=0.7095 | Δacc=+0.3504
[Student] epoch=3 train_loss=1.5257 val_loss=0.8154 val_acc=0.7507
[Monitor][student] epoch 3/60 | train_loss=1.5257 | val_loss=0.8154 | val_acc=0.7507 | Δacc=+0.0412
[Student] epoch=4 train_loss=1.2534 val_loss=0.7928 val_acc=0.7587
[Monitor][student] epoch 4/60 | train_loss=1.2534 | val_loss=0.7928 | val_acc=0.7587 | Δacc=+0.0079
[Student] epoch=5 train_loss=1.1222 val_loss=0.8267 val_acc=0.7760
[Monitor][student] epoch 5/60 | train_loss=1.1222 | val_loss=0.8267 | val_acc=0.7760 | Δacc=+0.0173
[Student] epoch=6 train_loss=1.0242 val_loss=0.8430 val_acc=0.7775
[Monitor][student] epoch 6/60 | train_loss=1.0242 | val_loss=0.8430 | val_acc=0.7775 | Δacc=+0.0014
[Student] epoch=7 train_loss=0.9370 val_loss=0.7857 val_acc=0.7984
[Monitor][student] epoch 7/60 | train_loss=0.9370 | val_loss=0.7857 | val_acc=0.7984 | Δacc=+0.0210
[Student] epoch=8 train_loss=0.8636 val_loss=0.6910 val_acc=0.8092
[Monitor][student] epoch 8/60 | train_loss=0.8636 | val_loss=0.6910 | val_acc=0.8092 | Δacc=+0.0108
[Student] epoch=9 train_loss=0.7473 val_loss=0.7600 val_acc=0.8230
[Monitor][student] epoch 9/60 | train_loss=0.7473 | val_loss=0.7600 | val_acc=0.8230 | Δacc=+0.0137
[Student] epoch=10 train_loss=0.7149 val_loss=0.7763 val_acc=0.8143
[Monitor][student] epoch 10/60 | train_loss=0.7149 | val_loss=0.7763 | val_acc=0.8143 | Δacc=-0.0087
[Student] epoch=11 train_loss=0.6409 val_loss=0.7618 val_acc=0.8208
[Monitor][student] epoch 11/60 | train_loss=0.6409 | val_loss=0.7618 | val_acc=0.8208 | Δacc=+0.0065
[Student] epoch=12 train_loss=0.5117 val_loss=0.8604 val_acc=0.8201
[Monitor][student] epoch 12/60 | train_loss=0.5117 | val_loss=0.8604 | val_acc=0.8201 | Δacc=-0.0007
[Student] epoch=13 train_loss=0.3721 val_loss=0.8663 val_acc=0.8360
[Monitor][student] epoch 13/60 | train_loss=0.3721 | val_loss=0.8663 | val_acc=0.8360 | Δacc=+0.0159
[Student] epoch=14 train_loss=0.3337 val_loss=0.8790 val_acc=0.8338
[Monitor][student] epoch 14/60 | train_loss=0.3337 | val_loss=0.8790 | val_acc=0.8338 | Δacc=-0.0022
[Student] epoch=15 train_loss=0.2650 val_loss=0.8814 val_acc=0.8338
[Monitor][student] epoch 15/60 | train_loss=0.2650 | val_loss=0.8814 | val_acc=0.8338 | Δacc=+0.0000
[Student] epoch=16 train_loss=0.2014 val_loss=0.9795 val_acc=0.8396
[Monitor][student] epoch 16/60 | train_loss=0.2014 | val_loss=0.9795 | val_acc=0.8396 | Δacc=+0.0058
[Student] epoch=17 train_loss=0.1910 val_loss=0.9850 val_acc=0.8403
[Monitor][student] epoch 17/60 | train_loss=0.1910 | val_loss=0.9850 | val_acc=0.8403 | Δacc=+0.0007
[Student] epoch=18 train_loss=0.1630 val_loss=0.9667 val_acc=0.8374
[Monitor][student] epoch 18/60 | train_loss=0.1630 | val_loss=0.9667 | val_acc=0.8374 | Δacc=-0.0029
[Student] epoch=19 train_loss=0.1285 val_loss=1.0283 val_acc=0.8418
[Monitor][student] epoch 19/60 | train_loss=0.1285 | val_loss=1.0283 | val_acc=0.8418 | Δacc=+0.0043
[Student] epoch=20 train_loss=0.1404 val_loss=1.0295 val_acc=0.8439
[Monitor][student] epoch 20/60 | train_loss=0.1404 | val_loss=1.0295 | val_acc=0.8439 | Δacc=+0.0022
[Student] epoch=21 train_loss=0.1367 val_loss=1.0146 val_acc=0.8461
[Monitor][student] epoch 21/60 | train_loss=0.1367 | val_loss=1.0146 | val_acc=0.8461 | Δacc=+0.0022
[Student] epoch=22 train_loss=0.1199 val_loss=1.0304 val_acc=0.8454
[Monitor][student] epoch 22/60 | train_loss=0.1199 | val_loss=1.0304 | val_acc=0.8454 | Δacc=-0.0007
[Student] epoch=23 train_loss=0.1201 val_loss=1.0623 val_acc=0.8418
[Monitor][student] epoch 23/60 | train_loss=0.1201 | val_loss=1.0623 | val_acc=0.8418 | Δacc=-0.0036
[Student] epoch=24 train_loss=0.0916 val_loss=1.0458 val_acc=0.8454
[Monitor][student] epoch 24/60 | train_loss=0.0916 | val_loss=1.0458 | val_acc=0.8454 | Δacc=+0.0036
[Student] epoch=25 train_loss=0.0951 val_loss=1.0544 val_acc=0.8418
[Monitor][student] epoch 25/60 | train_loss=0.0951 | val_loss=1.0544 | val_acc=0.8418 | Δacc=-0.0036
[Student] epoch=26 train_loss=0.1060 val_loss=1.0068 val_acc=0.8447
[Monitor][student] epoch 26/60 | train_loss=0.1060 | val_loss=1.0068 | val_acc=0.8447 | Δacc=+0.0029
[Student] epoch=27 train_loss=0.0908 val_loss=1.0131 val_acc=0.8439
[Monitor][student] epoch 27/60 | train_loss=0.0908 | val_loss=1.0131 | val_acc=0.8439 | Δacc=-0.0007
[Student] epoch=28 train_loss=0.0902 val_loss=1.0456 val_acc=0.8432
[Monitor][student] epoch 28/60 | train_loss=0.0902 | val_loss=1.0456 | val_acc=0.8432 | Δacc=-0.0007
[Student] epoch=29 train_loss=0.0887 val_loss=1.0392 val_acc=0.8497
[Monitor][student] epoch 29/60 | train_loss=0.0887 | val_loss=1.0392 | val_acc=0.8497 | Δacc=+0.0065
[Student] epoch=30 train_loss=0.0793 val_loss=1.0335 val_acc=0.8425
[Monitor][student] epoch 30/60 | train_loss=0.0793 | val_loss=1.0335 | val_acc=0.8425 | Δacc=-0.0072
[Student] epoch=31 train_loss=0.0930 val_loss=1.0193 val_acc=0.8425
[Monitor][student] epoch 31/60 | train_loss=0.0930 | val_loss=1.0193 | val_acc=0.8425 | Δacc=+0.0000
[Student] epoch=32 train_loss=0.0845 val_loss=1.0175 val_acc=0.8461
[Monitor][student] epoch 32/60 | train_loss=0.0845 | val_loss=1.0175 | val_acc=0.8461 | Δacc=+0.0036
[Student] epoch=33 train_loss=0.0794 val_loss=1.0507 val_acc=0.8512
[Monitor][student] epoch 33/60 | train_loss=0.0794 | val_loss=1.0507 | val_acc=0.8512 | Δacc=+0.0051
[Student] epoch=34 train_loss=0.0863 val_loss=1.0314 val_acc=0.8454
[Monitor][student] epoch 34/60 | train_loss=0.0863 | val_loss=1.0314 | val_acc=0.8454 | Δacc=-0.0058
[Student] epoch=35 train_loss=0.0980 val_loss=1.0332 val_acc=0.8454
[Monitor][student] epoch 35/60 | train_loss=0.0980 | val_loss=1.0332 | val_acc=0.8454 | Δacc=+0.0000
[Student] epoch=36 train_loss=0.0832 val_loss=1.0024 val_acc=0.8425
[Monitor][student] epoch 36/60 | train_loss=0.0832 | val_loss=1.0024 | val_acc=0.8425 | Δacc=-0.0029
[Student] epoch=37 train_loss=0.0992 val_loss=1.0248 val_acc=0.8447
[Monitor][student] epoch 37/60 | train_loss=0.0992 | val_loss=1.0248 | val_acc=0.8447 | Δacc=+0.0022
[Student] epoch=38 train_loss=0.0818 val_loss=1.0241 val_acc=0.8475
[Monitor][student] epoch 38/60 | train_loss=0.0818 | val_loss=1.0241 | val_acc=0.8475 | Δacc=+0.0029
[Student] epoch=39 train_loss=0.1363 val_loss=1.0279 val_acc=0.8439
[Monitor][student] epoch 39/60 | train_loss=0.1363 | val_loss=1.0279 | val_acc=0.8439 | Δacc=-0.0036
[Student] epoch=40 train_loss=0.0896 val_loss=1.0365 val_acc=0.8432
[Monitor][student] epoch 40/60 | train_loss=0.0896 | val_loss=1.0365 | val_acc=0.8432 | Δacc=-0.0007
[Student] epoch=41 train_loss=0.0833 val_loss=1.0630 val_acc=0.8497
[Monitor][student] epoch 41/60 | train_loss=0.0833 | val_loss=1.0630 | val_acc=0.8497 | Δacc=+0.0065
[Student] epoch=42 train_loss=0.0808 val_loss=1.0540 val_acc=0.8461
[Monitor][student] epoch 42/60 | train_loss=0.0808 | val_loss=1.0540 | val_acc=0.8461 | Δacc=-0.0036
[Student] epoch=43 train_loss=0.0791 val_loss=1.0216 val_acc=0.8461
[Monitor][student] epoch 43/60 | train_loss=0.0791 | val_loss=1.0216 | val_acc=0.8461 | Δacc=+0.0000
[Student] epoch=44 train_loss=0.0949 val_loss=1.0328 val_acc=0.8461
[Monitor][student] epoch 44/60 | train_loss=0.0949 | val_loss=1.0328 | val_acc=0.8461 | Δacc=+0.0000
[Student] epoch=45 train_loss=0.0863 val_loss=1.0830 val_acc=0.8512
[Monitor][student] epoch 45/60 | train_loss=0.0863 | val_loss=1.0830 | val_acc=0.8512 | Δacc=+0.0051
[Student] epoch=46 train_loss=0.0857 val_loss=1.0800 val_acc=0.8410
[Monitor][student] epoch 46/60 | train_loss=0.0857 | val_loss=1.0800 | val_acc=0.8410 | Δacc=-0.0101
[Student] epoch=47 train_loss=0.0865 val_loss=1.0548 val_acc=0.8454
[Monitor][student] epoch 47/60 | train_loss=0.0865 | val_loss=1.0548 | val_acc=0.8454 | Δacc=+0.0043
[Student] epoch=48 train_loss=0.0868 val_loss=1.0161 val_acc=0.8432
[Monitor][student] epoch 48/60 | train_loss=0.0868 | val_loss=1.0161 | val_acc=0.8432 | Δacc=-0.0022
[Student] epoch=49 train_loss=0.0786 val_loss=1.0646 val_acc=0.8425
[Monitor][student] epoch 49/60 | train_loss=0.0786 | val_loss=1.0646 | val_acc=0.8425 | Δacc=-0.0007
[Student] epoch=50 train_loss=0.0735 val_loss=1.0349 val_acc=0.8454
[Monitor][student] epoch 50/60 | train_loss=0.0735 | val_loss=1.0349 | val_acc=0.8454 | Δacc=+0.0029
[Student] epoch=51 train_loss=0.0979 val_loss=1.0555 val_acc=0.8468
[Monitor][student] epoch 51/60 | train_loss=0.0979 | val_loss=1.0555 | val_acc=0.8468 | Δacc=+0.0014
[Student] epoch=52 train_loss=0.0784 val_loss=1.0166 val_acc=0.8432
[Monitor][student] epoch 52/60 | train_loss=0.0784 | val_loss=1.0166 | val_acc=0.8432 | Δacc=-0.0036
[Student] epoch=53 train_loss=0.0787 val_loss=1.0372 val_acc=0.8439
[Monitor][student] epoch 53/60 | train_loss=0.0787 | val_loss=1.0372 | val_acc=0.8439 | Δacc=+0.0007
[Student] epoch=54 train_loss=0.0734 val_loss=1.0331 val_acc=0.8410
[Monitor][student] epoch 54/60 | train_loss=0.0734 | val_loss=1.0331 | val_acc=0.8410 | Δacc=-0.0029
[Student] epoch=55 train_loss=0.0741 val_loss=1.0440 val_acc=0.8432
[Monitor][student] epoch 55/60 | train_loss=0.0741 | val_loss=1.0440 | val_acc=0.8432 | Δacc=+0.0022
[Student] epoch=56 train_loss=0.1012 val_loss=1.0669 val_acc=0.8382
[Monitor][student] epoch 56/60 | train_loss=0.1012 | val_loss=1.0669 | val_acc=0.8382 | Δacc=-0.0051
[Student] epoch=57 train_loss=0.0842 val_loss=1.0422 val_acc=0.8461
[Monitor][student] epoch 57/60 | train_loss=0.0842 | val_loss=1.0422 | val_acc=0.8461 | Δacc=+0.0079
[Student] epoch=58 train_loss=0.0816 val_loss=1.0610 val_acc=0.8447
[Monitor][student] epoch 58/60 | train_loss=0.0816 | val_loss=1.0610 | val_acc=0.8447 | Δacc=-0.0014
[Student] epoch=59 train_loss=0.0852 val_loss=1.0728 val_acc=0.8475
[Monitor][student] epoch 59/60 | train_loss=0.0852 | val_loss=1.0728 | val_acc=0.8475 | Δacc=+0.0029
[Student] epoch=60 train_loss=0.0813 val_loss=1.0887 val_acc=0.8483
[Monitor][student] epoch 60/60 | train_loss=0.0813 | val_loss=1.0887 | val_acc=0.8483 | Δacc=+0.0007
[Monitor] <<< Stage 'student' finished after 60 epochs | final acc=0.8483

✅ 学生模型训练完成！检查点: checkpoints/student_sd_mkd.pth

======================================================================
训练完成！
======================================================================

